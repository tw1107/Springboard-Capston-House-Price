{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62e84822",
   "metadata": {},
   "source": [
    "# Pre-processing & Training Data Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ca1f96",
   "metadata": {},
   "source": [
    "## 1. Imports packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b94db7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Libraries\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.dummy import DummyRegressor\n",
    "import datetime\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import uniform, randint, skew, f_oneway\n",
    "# from scipy.stats import skew, f_oneway\n",
    "\n",
    "# Definitions\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "%matplotlib inline\n",
    "#njobs = 4\n",
    "\n",
    "from library.sb_utils import save_file\n",
    "print(\"Loaded Libraries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1df8bf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC, Ridge\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler, scale, StandardScaler, MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, cross_validate, GridSearchCV, RandomizedSearchCV, learning_curve\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, make_scorer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c5c08ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98775efa",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de849e3f",
   "metadata": {},
   "source": [
    "We will use the cleaned data in EDA step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e84b42ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data have  1456  rows and  79  columns\n",
      "\n",
      "column names: \n",
      "\n",
      "MSSubClass\n",
      "MSZoning\n",
      "LotFrontage\n",
      "LotArea\n",
      "Street\n",
      "Alley\n",
      "LotShape\n",
      "LandContour\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition1\n",
      "Condition2\n",
      "BldgType\n",
      "HouseStyle\n",
      "OverallQual\n",
      "OverallCond\n",
      "YearBuilt\n",
      "YearRemodAdd\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "MasVnrArea\n",
      "ExterQual\n",
      "ExterCond\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinSF1\n",
      "BsmtFinType2\n",
      "BsmtFinSF2\n",
      "BsmtUnfSF\n",
      "TotalBsmtSF\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "1stFlrSF\n",
      "2ndFlrSF\n",
      "LowQualFinSF\n",
      "GrLivArea\n",
      "BsmtFullBath\n",
      "BsmtHalfBath\n",
      "FullBath\n",
      "HalfBath\n",
      "BedroomAbvGr\n",
      "KitchenAbvGr\n",
      "KitchenQual\n",
      "TotRmsAbvGrd\n",
      "Functional\n",
      "Fireplaces\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageYrBlt\n",
      "GarageFinish\n",
      "GarageCars\n",
      "GarageArea\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n",
      "WoodDeckSF\n",
      "OpenPorchSF\n",
      "EnclosedPorch\n",
      "3SsnPorch\n",
      "ScreenPorch\n",
      "PoolArea\n",
      "PoolQC\n",
      "Fence\n",
      "MiscFeature\n",
      "MiscVal\n",
      "MoSold\n",
      "YrSold\n",
      "SaleType\n",
      "SaleCondition\n",
      "SalePrice\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = pd.read_csv('../data/house_price_preprocessing_data.csv')\n",
    "df_cleaned.shape\n",
    "\n",
    "print('The data have ', df_cleaned.shape[0], ' rows and ', df_cleaned.shape[1], ' columns\\n')\n",
    "print('column names: \\n')\n",
    "print('\\n'.join(list(df_cleaned.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1877bf23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.000</td>\n",
       "      <td>8450</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>12.248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.000</td>\n",
       "      <td>9600</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>FR2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>12.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.000</td>\n",
       "      <td>11250</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>12.317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.000</td>\n",
       "      <td>9550</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Corner</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>11.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.000</td>\n",
       "      <td>14260</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>FR2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>12.429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea  Street Alley  LotShape  \\\n",
       "0          60       RL       65.000     8450       2    No         4   \n",
       "1          20       RL       80.000     9600       2    No         4   \n",
       "2          60       RL       68.000    11250       2    No         3   \n",
       "3          70       RL       60.000     9550       2    No         3   \n",
       "4          60       RL       84.000    14260       2    No         3   \n",
       "\n",
       "  LandContour LotConfig  LandSlope  ... PoolArea PoolQC Fence MiscFeature  \\\n",
       "0         Lvl    Inside          3  ...        0     No    No          No   \n",
       "1         Lvl       FR2          3  ...        0     No    No          No   \n",
       "2         Lvl    Inside          3  ...        0     No    No          No   \n",
       "3         Lvl    Corner          3  ...        0     No    No          No   \n",
       "4         Lvl       FR2          3  ...        0     No    No          No   \n",
       "\n",
       "  MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0       0       2    2008        WD         Normal    12.248  \n",
       "1       0       5    2007        WD         Normal    12.109  \n",
       "2       0       9    2008        WD         Normal    12.317  \n",
       "3       0       2    2006        WD        Abnorml    11.849  \n",
       "4       0      12    2008        WD         Normal    12.429  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849ede05",
   "metadata": {},
   "source": [
    "## 3. Determine the importance of categorical/numeric features vs target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cff9bd",
   "metadata": {},
   "source": [
    "#### 3.1 Use Anova to rank the categorical features vs our target variable SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d519a90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GarageFinish: F-statistic: 299.42, p-value: 0.00\n",
      "CentralAir: F-statistic: 207.92, p-value: 0.00\n",
      "FireplaceQu: F-statistic: 129.58, p-value: 0.00\n",
      "Foundation: F-statistic: 126.84, p-value: 0.00\n",
      "GarageType: F-statistic: 123.43, p-value: 0.00\n",
      "MasVnrType: F-statistic: 90.47, p-value: 0.00\n",
      "Neighborhood: F-statistic: 79.05, p-value: 0.00\n",
      "MSZoning: F-statistic: 78.41, p-value: 0.00\n",
      "BsmtFinType1: F-statistic: 70.55, p-value: 0.00\n",
      "BsmtExposure: F-statistic: 62.15, p-value: 0.00\n",
      "GarageCond: F-statistic: 49.91, p-value: 0.00\n",
      "GarageQual: F-statistic: 48.39, p-value: 0.00\n",
      "SaleCondition: F-statistic: 45.90, p-value: 0.00\n",
      "Electrical: F-statistic: 39.17, p-value: 0.00\n",
      "BsmtCond: F-statistic: 34.95, p-value: 0.00\n",
      "SaleType: F-statistic: 25.80, p-value: 0.00\n",
      "Exterior1st: F-statistic: 23.96, p-value: 0.00\n",
      "HouseStyle: F-statistic: 23.07, p-value: 0.00\n",
      "Alley: F-statistic: 20.79, p-value: 0.00\n",
      "Exterior2nd: F-statistic: 20.19, p-value: 0.00\n",
      "Fence: F-statistic: 17.19, p-value: 0.00\n",
      "BldgType: F-statistic: 15.24, p-value: 0.00\n",
      "LandContour: F-statistic: 13.28, p-value: 0.00\n",
      "RoofStyle: F-statistic: 12.92, p-value: 0.00\n",
      "BsmtFinType2: F-statistic: 11.01, p-value: 0.00\n",
      "Heating: F-statistic: 10.02, p-value: 0.00\n",
      "LotConfig: F-statistic: 8.87, p-value: 0.00\n",
      "Condition1: F-statistic: 8.11, p-value: 0.00\n",
      "MiscFeature: F-statistic: 3.62, p-value: 0.01\n",
      "Condition2: F-statistic: 2.80, p-value: 0.01\n",
      "RoofMatl: F-statistic: 2.79, p-value: 0.01\n",
      "PoolQC: F-statistic: 0.81, p-value: 0.49\n"
     ]
    }
   ],
   "source": [
    "# Separate the feature and target variable\n",
    "target = df_cleaned['SalePrice']\n",
    "\n",
    "anova_results = {}\n",
    "\n",
    "for feature in df_cleaned.select_dtypes(include=['object']):\n",
    "    # Perform ANOVA test for the current feature\n",
    "    f_statistic, p_value = f_oneway(*(target[df_cleaned[feature] == category] for category in df_cleaned[feature].unique()))\n",
    "    # Store the ANOVA results for the current feature in the dictionary\n",
    "    anova_results[feature] = {'f_statistic': f_statistic, 'p_value': p_value}\n",
    "\n",
    "# Sort the ANOVA results by the F-statistic in descending order\n",
    "sorted_results = sorted(anova_results.items(), key=lambda x: x[1]['f_statistic'], reverse=True)\n",
    "\n",
    "# Print the sorted ANOVA results\n",
    "for feature, results in sorted_results:\n",
    "    print('{}: F-statistic: {:.2f}, p-value: {:.2f}'.format(feature, results['f_statistic'], results['p_value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0272dcf8",
   "metadata": {},
   "source": [
    "#### 3.2 Use Pearson correlation coefficient to measure the linear association between numeric features and  target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72e1b39f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Correlation Coefficient\n",
      "SalePrice                        1.000\n",
      "OverallQual                      0.819\n",
      "GrLivArea                        0.719\n",
      "ExterQual                        0.681\n",
      "GarageCars                       0.680\n",
      "KitchenQual                      0.667\n",
      "GarageArea                       0.655\n",
      "TotalBsmtSF                      0.642\n",
      "BsmtQual                         0.615\n",
      "1stFlrSF                         0.614\n",
      "FullBath                         0.591\n",
      "YearBuilt                        0.589\n",
      "YearRemodAdd                     0.569\n",
      "TotRmsAbvGrd                     0.533\n",
      "Fireplaces                       0.487\n",
      "HeatingQC                        0.474\n",
      "MasVnrArea                       0.426\n",
      "BsmtFinSF1                       0.383\n",
      "LotFrontage                      0.361\n",
      "GarageYrBlt                      0.351\n",
      "WoodDeckSF                       0.331\n",
      "OpenPorchSF                      0.327\n",
      "HalfBath                         0.311\n",
      "2ndFlrSF                         0.307\n",
      "PavedDrive                       0.306\n",
      "LotArea                          0.259\n",
      "BsmtFullBath                     0.239\n",
      "BsmtUnfSF                        0.223\n",
      "BedroomAbvGr                     0.204\n",
      "Functional                       0.136\n",
      "ScreenPorch                      0.124\n",
      "MoSold                           0.062\n",
      "Street                           0.058\n",
      "3SsnPorch                        0.056\n",
      "ExterCond                        0.051\n",
      "PoolArea                         0.041\n",
      "BsmtFinSF2                       0.006\n",
      "BsmtHalfBath                    -0.015\n",
      "MiscVal                         -0.020\n",
      "YrSold                          -0.034\n",
      "OverallCond                     -0.037\n",
      "LowQualFinSF                    -0.038\n",
      "LandSlope                       -0.040\n",
      "MSSubClass                      -0.075\n",
      "KitchenAbvGr                    -0.148\n",
      "EnclosedPorch                   -0.149\n",
      "LotShape                        -0.286\n"
     ]
    }
   ],
   "source": [
    "# Select the numeric features and the target variable\n",
    "num_features = df_cleaned.select_dtypes(exclude=['object']).columns\n",
    "target_var = 'SalePrice'\n",
    "\n",
    "# Calculate the Pearson correlation coefficient between each numeric feature and the target variable\n",
    "corr_results = {}\n",
    "for feature in num_features:\n",
    "    corr_coef = df_cleaned[feature].corr(df_cleaned[target_var])\n",
    "    corr_results[feature] = corr_coef\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "result_df = pd.DataFrame.from_dict(corr_results, orient='index', columns=['Correlation Coefficient'])\n",
    "\n",
    "# Sort the DataFrame by correlation coefficient in descending order\n",
    "result_df = result_df.sort_values(by='Correlation Coefficient', ascending=False)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b121a",
   "metadata": {},
   "source": [
    "## 4. Encode some categorical features as ordered numbers when there is information in the order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc93be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_cleaned\n",
    "\n",
    "# Encode some categorical features as ordered numbers when there is information in the order\n",
    "train = train.replace({\"Alley\" : {\"Grvl\" : 1, \"Pave\" : 2},\n",
    "                       \"BsmtCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"BsmtExposure\" : {\"No\" : 0, \"Mn\" : 1, \"Av\": 2, \"Gd\" : 3},\n",
    "                       \"BsmtFinType1\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \n",
    "                                         \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "                       \"BsmtFinType2\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \n",
    "                                         \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "                       \"BsmtQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"ExterCond\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "                       \"ExterQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "                       \"FireplaceQu\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"Functional\" : {\"Sal\" : 1, \"Sev\" : 2, \"Maj2\" : 3, \"Maj1\" : 4, \"Mod\": 5, \n",
    "                                       \"Min2\" : 6, \"Min1\" : 7, \"Typ\" : 8},\n",
    "                       \"GarageCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"GarageQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"HeatingQC\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"KitchenQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"LandSlope\" : {\"Sev\" : 1, \"Mod\" : 2, \"Gtl\" : 3},\n",
    "                       \"LotShape\" : {\"IR3\" : 1, \"IR2\" : 2, \"IR1\" : 3, \"Reg\" : 4},\n",
    "                       \"PavedDrive\" : {\"N\" : 0, \"P\" : 1, \"Y\" : 2},\n",
    "                       \"PoolQC\" : {\"No\" : 0, \"Fa\" : 1, \"TA\" : 2, \"Gd\" : 3, \"Ex\" : 4},\n",
    "                       \"Street\" : {\"Grvl\" : 1, \"Pave\" : 2},\n",
    "                       \"Utilities\" : {\"ELO\" : 1, \"NoSeWa\" : 2, \"NoSewr\" : 3, \"AllPub\" : 4}}\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f525178",
   "metadata": {},
   "source": [
    "## 5. Create new features\n",
    "\n",
    "Simplifications of existing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b16834a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features\n",
    "# 1* Simplifications of existing features\n",
    "train[\"SimplOverallQual\"] = train.OverallQual.replace({1 : 1, 2 : 1, 3 : 1, # bad\n",
    "                                                       4 : 2, 5 : 2, 6 : 2, # average\n",
    "                                                       7 : 3, 8 : 3, 9 : 3, 10 : 3 # good\n",
    "                                                      })\n",
    "train[\"SimplOverallCond\"] = train.OverallCond.replace({1 : 1, 2 : 1, 3 : 1, # bad\n",
    "                                                       4 : 2, 5 : 2, 6 : 2, # average\n",
    "                                                       7 : 3, 8 : 3, 9 : 3, 10 : 3 # good\n",
    "                                                      })\n",
    "train[\"SimplPoolQC\"] = train.PoolQC.replace({1 : 1, 2 : 1, # average\n",
    "                                             3 : 2, 4 : 2 # good\n",
    "                                            })\n",
    "train[\"SimplGarageCond\"] = train.GarageCond.replace({1 : 1, # bad\n",
    "                                                     2 : 1, 3 : 1, # average\n",
    "                                                     4 : 2, 5 : 2 # good\n",
    "                                                    })\n",
    "train[\"SimplGarageQual\"] = train.GarageQual.replace({1 : 1, # bad\n",
    "                                                     2 : 1, 3 : 1, # average\n",
    "                                                     4 : 2, 5 : 2 # good\n",
    "                                                    })\n",
    "train[\"SimplFireplaceQu\"] = train.FireplaceQu.replace({1 : 1, # bad\n",
    "                                                       2 : 1, 3 : 1, # average\n",
    "                                                       4 : 2, 5 : 2 # good\n",
    "                                                      })\n",
    "train[\"SimplFireplaceQu\"] = train.FireplaceQu.replace({1 : 1, # bad\n",
    "                                                       2 : 1, 3 : 1, # average\n",
    "                                                       4 : 2, 5 : 2 # good\n",
    "                                                      })\n",
    "train[\"SimplFunctional\"] = train.Functional.replace({1 : 1, 2 : 1, # bad\n",
    "                                                     3 : 2, 4 : 2, # major\n",
    "                                                     5 : 3, 6 : 3, 7 : 3, # minor\n",
    "                                                     8 : 4 # typical\n",
    "                                                    })\n",
    "train[\"SimplKitchenQual\"] = train.KitchenQual.replace({1 : 1, # bad\n",
    "                                                       2 : 1, 3 : 1, # average\n",
    "                                                       4 : 2, 5 : 2 # good\n",
    "                                                      })\n",
    "train[\"SimplHeatingQC\"] = train.HeatingQC.replace({1 : 1, # bad\n",
    "                                                   2 : 1, 3 : 1, # average\n",
    "                                                   4 : 2, 5 : 2 # good\n",
    "                                                  })\n",
    "train[\"SimplBsmtFinType1\"] = train.BsmtFinType1.replace({1 : 1, # unfinished\n",
    "                                                         2 : 1, 3 : 1, # rec room\n",
    "                                                         4 : 2, 5 : 2, 6 : 2 # living quarters\n",
    "                                                        })\n",
    "train[\"SimplBsmtFinType2\"] = train.BsmtFinType2.replace({1 : 1, # unfinished\n",
    "                                                         2 : 1, 3 : 1, # rec room\n",
    "                                                         4 : 2, 5 : 2, 6 : 2 # living quarters\n",
    "                                                        })\n",
    "train[\"SimplBsmtCond\"] = train.BsmtCond.replace({1 : 1, # bad\n",
    "                                                 2 : 1, 3 : 1, # average\n",
    "                                                 4 : 2, 5 : 2 # good\n",
    "                                                })\n",
    "train[\"SimplBsmtQual\"] = train.BsmtQual.replace({1 : 1, # bad\n",
    "                                                 2 : 1, 3 : 1, # average\n",
    "                                                 4 : 2, 5 : 2 # good\n",
    "                                                })\n",
    "train[\"SimplExterCond\"] = train.ExterCond.replace({1 : 1, # bad\n",
    "                                                   2 : 1, 3 : 1, # average\n",
    "                                                   4 : 2, 5 : 2 # good\n",
    "                                                  })\n",
    "train[\"SimplExterQual\"] = train.ExterQual.replace({1 : 1, # bad\n",
    "                                                   2 : 1, 3 : 1, # average\n",
    "                                                   4 : 2, 5 : 2 # good\n",
    "                                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5dbf244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find most important features relative to target\n",
      "SalePrice           1.000\n",
      "OverallQual         0.819\n",
      "GrLivArea           0.719\n",
      "SimplOverallQual    0.708\n",
      "ExterQual           0.681\n",
      "GarageCars          0.680\n",
      "KitchenQual         0.667\n",
      "GarageArea          0.655\n",
      "TotalBsmtSF         0.642\n",
      "SimplExterQual      0.636\n",
      "BsmtQual            0.615\n",
      "1stFlrSF            0.614\n",
      "SimplKitchenQual    0.610\n",
      "SimplBsmtQual       0.594\n",
      "FullBath            0.591\n",
      "YearBuilt           0.589\n",
      "YearRemodAdd        0.569\n",
      "TotRmsAbvGrd        0.533\n",
      "Fireplaces          0.487\n",
      "HeatingQC           0.474\n",
      "MasVnrArea          0.426\n",
      "SimplHeatingQC      0.398\n",
      "BsmtFinSF1          0.383\n",
      "LotFrontage         0.361\n",
      "GarageYrBlt         0.351\n",
      "WoodDeckSF          0.331\n",
      "OpenPorchSF         0.327\n",
      "HalfBath            0.311\n",
      "2ndFlrSF            0.307\n",
      "PavedDrive          0.306\n",
      "LotArea             0.259\n",
      "BsmtFullBath        0.239\n",
      "BsmtUnfSF           0.223\n",
      "BedroomAbvGr        0.204\n",
      "SimplFunctional     0.137\n",
      "Functional          0.136\n",
      "ScreenPorch         0.124\n",
      "MoSold              0.062\n",
      "Street              0.058\n",
      "3SsnPorch           0.056\n",
      "ExterCond           0.051\n",
      "PoolArea            0.041\n",
      "BsmtFinSF2          0.006\n",
      "BsmtHalfBath       -0.015\n",
      "MiscVal            -0.020\n",
      "SimplOverallCond   -0.028\n",
      "YrSold             -0.034\n",
      "OverallCond        -0.037\n",
      "LowQualFinSF       -0.038\n",
      "LandSlope          -0.040\n",
      "SimplExterCond     -0.042\n",
      "MSSubClass         -0.075\n",
      "KitchenAbvGr       -0.148\n",
      "EnclosedPorch      -0.149\n",
      "LotShape           -0.286\n",
      "Name: SalePrice, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Find most important features relative to target\n",
    "print(\"Find most important features relative to target\")\n",
    "corr = train.corr()\n",
    "corr.sort_values([\"SalePrice\"], ascending = False, inplace = True)\n",
    "print(corr.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbaada4",
   "metadata": {},
   "source": [
    "## 6. Differentiate numerical features (minus the target) and categorical features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a01c29c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features : 54\n",
      "Categorical features : 39\n"
     ]
    }
   ],
   "source": [
    "categorical_features = train.select_dtypes(include = [\"object\"]).columns\n",
    "numerical_features = train.select_dtypes(exclude = [\"object\"]).columns\n",
    "numerical_features = numerical_features.drop(\"SalePrice\")\n",
    "print(\"Numerical features : \" + str(len(numerical_features)))\n",
    "print(\"Categorical features : \" + str(len(categorical_features)))\n",
    "train_num = train[numerical_features]\n",
    "train_cat = train[categorical_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f10a38",
   "metadata": {},
   "source": [
    "## 7. Log transform of the skewed numerical features to lessen impact of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25be13a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 skewed numerical features to log transform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3t/zg2pg4h96j33j992z6f26cgh0000gn/T/ipykernel_27479/3352021519.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_num[skewed_features] = np.log1p(train_num[skewed_features])\n"
     ]
    }
   ],
   "source": [
    "# As a general rule of thumb, a skewness with an absolute value > 0.5 is considered at least moderately skewed\n",
    "skewness = train_num.apply(lambda x: skew(x))\n",
    "skewness = skewness[abs(skewness) > 0.5]\n",
    "print(str(skewness.shape[0]) + \" skewed numerical features to log transform\")\n",
    "skewed_features = skewness.index\n",
    "train_num[skewed_features] = np.log1p(train_num[skewed_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935a2a8b",
   "metadata": {},
   "source": [
    "## 8.Transformation of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40fff1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSZoning_C (all)</th>\n",
       "      <th>MSZoning_FV</th>\n",
       "      <th>MSZoning_RH</th>\n",
       "      <th>MSZoning_RL</th>\n",
       "      <th>MSZoning_RM</th>\n",
       "      <th>Alley_1</th>\n",
       "      <th>Alley_2</th>\n",
       "      <th>Alley_No</th>\n",
       "      <th>LandContour_Bnk</th>\n",
       "      <th>LandContour_HLS</th>\n",
       "      <th>...</th>\n",
       "      <th>SimplBsmtFinType2_2</th>\n",
       "      <th>SimplBsmtFinType2_3</th>\n",
       "      <th>SimplBsmtFinType2_4</th>\n",
       "      <th>SimplBsmtFinType2_5</th>\n",
       "      <th>SimplBsmtFinType2_6</th>\n",
       "      <th>SimplBsmtCond_0</th>\n",
       "      <th>SimplBsmtCond_1</th>\n",
       "      <th>SimplBsmtCond_2</th>\n",
       "      <th>SimplBsmtCond_3</th>\n",
       "      <th>SimplBsmtCond_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSZoning_C (all)  MSZoning_FV  MSZoning_RH  MSZoning_RL  MSZoning_RM  \\\n",
       "0                 0            0            0            1            0   \n",
       "1                 0            0            0            1            0   \n",
       "2                 0            0            0            1            0   \n",
       "3                 0            0            0            1            0   \n",
       "4                 0            0            0            1            0   \n",
       "\n",
       "   Alley_1  Alley_2  Alley_No  LandContour_Bnk  LandContour_HLS  ...  \\\n",
       "0        0        0         1                0                0  ...   \n",
       "1        0        0         1                0                0  ...   \n",
       "2        0        0         1                0                0  ...   \n",
       "3        0        0         1                0                0  ...   \n",
       "4        0        0         1                0                0  ...   \n",
       "\n",
       "   SimplBsmtFinType2_2  SimplBsmtFinType2_3  SimplBsmtFinType2_4  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   SimplBsmtFinType2_5  SimplBsmtFinType2_6  SimplBsmtCond_0  SimplBsmtCond_1  \\\n",
       "0                    0                    0                0                0   \n",
       "1                    0                    0                0                0   \n",
       "2                    0                    0                0                0   \n",
       "3                    0                    0                0                0   \n",
       "4                    0                    0                0                0   \n",
       "\n",
       "   SimplBsmtCond_2  SimplBsmtCond_3  SimplBsmtCond_4  \n",
       "0                0                1                0  \n",
       "1                0                1                0  \n",
       "2                0                1                0  \n",
       "3                0                0                1  \n",
       "4                0                1                0  \n",
       "\n",
       "[5 rows x 262 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy features for categorical values via one-hot encoding\n",
    "train_cat = pd.get_dummies(train_cat)\n",
    "\n",
    "train_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae76345",
   "metadata": {},
   "source": [
    "## 9. Split into testing and training datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6646b94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New number of features : 316\n",
      "X_train : (1164, 316)\n",
      "X_test : (292, 316)\n",
      "y_train : (1164,)\n",
      "y_test : (292,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Join categorical and numerical features\n",
    "X = pd.concat([train_num, train_cat], axis = 1)\n",
    "y = train.SalePrice\n",
    "print(\"New number of features : \" + str(X.shape[1]))\n",
    "\n",
    "# Partition the dataset in train + validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "print(\"X_train : \" + str(X_train.shape))\n",
    "print(\"X_test : \" + str(X_test.shape))\n",
    "print(\"y_train : \" + str(y_train.shape))\n",
    "print(\"y_test : \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf2719c",
   "metadata": {},
   "source": [
    "## 10.Standardize the magnitude of numeric features using a scaler \n",
    "\n",
    "Standardization cannot be done before train & test split, as we don't want to fit the StandardScaler on some observations that will later be used in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3020ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize numerical features\n",
    "stdSc = StandardScaler()\n",
    "X_train.loc[:, numerical_features] = stdSc.fit_transform(X_train.loc[:, numerical_features])\n",
    "X_test.loc[:, numerical_features] = stdSc.transform(X_test.loc[:, numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0638bd8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass        1.001\n",
       "LotFrontage       1.001\n",
       "LotArea           1.001\n",
       "Street            1.001\n",
       "LotShape          1.001\n",
       "                   ... \n",
       "SimplBsmtCond_0   0.025\n",
       "SimplBsmtCond_1   0.001\n",
       "SimplBsmtCond_2   0.030\n",
       "SimplBsmtCond_3   0.095\n",
       "SimplBsmtCond_4   0.046\n",
       "Length: 316, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db9c1850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass        1.029\n",
       "LotFrontage       1.070\n",
       "LotArea           0.987\n",
       "Street            0.801\n",
       "LotShape          0.597\n",
       "                   ... \n",
       "SimplBsmtCond_0   0.023\n",
       "SimplBsmtCond_1   0.003\n",
       "SimplBsmtCond_2   0.030\n",
       "SimplBsmtCond_3   0.081\n",
       "SimplBsmtCond_4   0.030\n",
       "Length: 316, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0e0b78",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "164a3395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC, Ridge\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler, scale, StandardScaler, MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, cross_validate, GridSearchCV, RandomizedSearchCV, learning_curve\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, make_scorer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from scipy.stats import randint as sp_randint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b79823",
   "metadata": {},
   "source": [
    "#### Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43cc3db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score on the testing data:  -6482216111064935.0\n",
      "RMSE score on the testing data:  31996739.15555886\n"
     ]
    }
   ],
   "source": [
    "# Create a Linear Regression object\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Calculate R2 and RMSE scores on the testing data\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"R2 score on the testing data: \", r2)\n",
    "print(\"RMSE score on the testing data: \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e184d3ac",
   "metadata": {},
   "source": [
    "Simple linear regression model perform poorly which is expected since we have too many features for a simple linear regression to  handle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7443ef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KFold object\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f5466c",
   "metadata": {},
   "source": [
    "#### Ridge w/ hyperparameter tuning - RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c426ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tsaijungwang/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 2 is smaller than n_iter=100. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'solver': 'sag', 'alpha': 0.0001}\n",
      "R2 score on the testing data:  0.9030865298972828\n",
      "RMSE score on the testing data:  0.12371889716735882\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter space\n",
    "ridge_param_grid = {\"alpha\": np.arange(0.0001, 1.0, 10),\n",
    "              \"solver\": [\"sag\",\"lsqr\"]}\n",
    "\n",
    "# Create a Ridge Regressor object\n",
    "ridge_model = Ridge()\n",
    "\n",
    "# Create a RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator=ridge_model, param_distributions=ridge_param_grid, n_iter=100, cv=kf)\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters: \", random_search.best_params_)\n",
    "\n",
    "# Train the Ridge Regressor with the best hyperparameters on the entire training set\n",
    "ridge_model = Ridge(**random_search.best_params_)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = ridge_model.predict(X_test)\n",
    "\n",
    "# Calculate R2 and RMSE scores on the testing data\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"R2 score on the testing data: \", r2)\n",
    "print(\"RMSE score on the testing data: \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c3ad48",
   "metadata": {},
   "source": [
    "#### Lasso w/ hyperparameter tuning - RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe7cfca1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tsaijungwang/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.372e-01, tolerance: 1.655e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/tsaijungwang/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e-01, tolerance: 1.677e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/tsaijungwang/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.492e-01, tolerance: 1.597e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/tsaijungwang/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e-01, tolerance: 1.614e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/tsaijungwang/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.138e-01, tolerance: 1.574e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/tsaijungwang/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.694e-01, tolerance: 1.819e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'alpha': 1e-05}\n",
      "R2 score on the testing data:  0.898276897868292\n",
      "RMSE score on the testing data:  0.12675169212441617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tsaijungwang/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.694e-01, tolerance: 1.819e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid\n",
    "lasso_params = {\"alpha\": np.linspace(0.00001, 1, 20)}\n",
    "\n",
    "# Create a Lasso Regressor object\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# Create a RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator=lasso_model, param_distributions=lasso_params, n_iter=20, cv=kf)\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters: \", random_search.best_params_)\n",
    "\n",
    "# Train the Lasso Regressor with the best hyperparameters on the entire training set\n",
    "lasso_model = Lasso(**random_search.best_params_)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = lasso_model.predict(X_test)\n",
    "\n",
    "# Calculate R2 and RMSE scores on the testing data\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"R2 score on the testing data: \", r2)\n",
    "print(\"RMSE score on the testing data: \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce052a5",
   "metadata": {},
   "source": [
    "#### ElasticNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a0d2da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'alpha': 0.02541912674409519, 'l1_ratio': 0.10789142699330445}\n",
      "Best R2 score:  0.9087384467239378\n",
      "R2 score on the testing data:  0.9039705214721778\n",
      "RMSE score on the testing data:  0.12315335657830474\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "en_param_dist = {\"alpha\": uniform(0, 1),\n",
    "              \"l1_ratio\": uniform(0, 1)}\n",
    "\n",
    "# Create an ElasticNet model object\n",
    "enet_model = ElasticNet()\n",
    "\n",
    "# Create a RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator=enet_model, param_distributions=en_param_dist, n_iter=100, cv=5, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters: \", random_search.best_params_)\n",
    "print(\"Best R2 score: \", random_search.best_score_)\n",
    "# print(\"Best RMSE score: \", -random_search.cv_results_['mean_test_rmse_score'][random_search.best_index_])\n",
    "\n",
    "\n",
    "# Train the ElasticNet model with the best hyperparameters on the entire training set\n",
    "enet_model = ElasticNet(**random_search.best_params_)\n",
    "enet_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = enet_model.predict(X_test)\n",
    "\n",
    "# Calculate R2 and RMSE scores on the testing data\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"R2 score on the testing data: \", r2)\n",
    "print(\"RMSE score on the testing data: \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8f4baf",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a3ae889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'colsample_bytree': 0.8531211135782482, 'gamma': 0.08134878064189976, 'learning_rate': 0.08483771408519192, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.6871353978780601}\n",
      "R2 score on the testing data:  0.8984794608311326\n",
      "RMSE score on the testing data:  0.12662542782273986\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "xg_param_dist = {\"learning_rate\": uniform(0, 1),\n",
    "              \"max_depth\": randint(1, 10),\n",
    "              \"min_child_weight\": randint(1, 10),\n",
    "              \"subsample\": uniform(0.5, 0.5),\n",
    "              \"colsample_bytree\": uniform(0.5, 0.5),\n",
    "              \"gamma\": uniform(0, 1)}\n",
    "\n",
    "# Create an XGBoost model object\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "# Create scorer objects for the R2 and RMSE scores\n",
    "scorers = {'r2_score': make_scorer(r2_score),\n",
    "           'rmse_score': make_scorer(mean_squared_error, squared=False)}\n",
    "\n",
    "# Create a RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator=xgb_model, \n",
    "                                   param_distributions=xg_param_dist, \n",
    "                                   n_iter=100, cv=5, \n",
    "                                   scoring=scorers, \n",
    "                                   refit='r2_score', \n",
    "                                   random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and the best scores\n",
    "print(\"Best hyperparameters: \", random_search.best_params_)\n",
    "# print(\"Best R2 score: \", random_search.best_score_)\n",
    "# print(\"Best RMSE score: \", -random_search.cv_results_['mean_test_rmse_score'][random_search.best_index_])\n",
    "\n",
    "# Train the XGBoost model with the best hyperparameters on the entire training set\n",
    "xgb_model = xgb.XGBRegressor(**random_search.best_params_)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate R2 and RMSE scores on the testing data\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"R2 score on the testing data: \", r2)\n",
    "print(\"RMSE score on the testing data: \", rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb177f73",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ad7569a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'learning_rate': 0.19438003399487302, 'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 9, 'n_estimators': 65}\n",
      "R2 score on the testing data:  0.8896990171563238\n",
      "RMSE score on the testing data:  0.13198776019290057\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "gb_param_dist = {\"learning_rate\": uniform(0, 1),\n",
    "              \"n_estimators\": randint(50, 100),\n",
    "              \"max_depth\": randint(1, 10),\n",
    "              \"min_samples_split\": randint(2, 10),\n",
    "              \"min_samples_leaf\": randint(1, 5)}\n",
    "\n",
    "# Create a Gradient Boosting Regressor object\n",
    "gbr_model = GradientBoostingRegressor()\n",
    "\n",
    "# Create a RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator=gbr_model, param_distributions=gb_param_dist, n_iter=100, cv=5, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters: \", random_search.best_params_)\n",
    "\n",
    "# Train the Gradient Boosting Regressor with the best hyperparameters on the entire training set\n",
    "gbr_model = GradientBoostingRegressor(**random_search.best_params_)\n",
    "gbr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = gbr_model.predict(X_test)\n",
    "\n",
    "# Calculate R2 and RMSE scores on the testing data\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"R2 score on the testing data: \", r2)\n",
    "print(\"RMSE score on the testing data: \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a403490d",
   "metadata": {},
   "source": [
    "#### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cebf72f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'learning_rate': 0.1, 'max_depth': 9, 'min_child_samples': 21, 'n_estimators': 178, 'num_leaves': 6}\n",
      "R2 score on the testing data:  0.8911525255663715\n",
      "RMSE score on the testing data:  0.13111523153865767\n"
     ]
    }
   ],
   "source": [
    "# Create a Light GBM Regressor object\n",
    "lgb_model = lgb.LGBMRegressor()\n",
    "\n",
    "# Define the parameter grid for the Light GBM Regressor\n",
    "lgb_param_dist = {\"num_leaves\": sp_randint(6, 50),\n",
    "              \"max_depth\": sp_randint(1, 20),\n",
    "              \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "              \"n_estimators\": sp_randint(50, 500),\n",
    "              \"min_child_samples\": sp_randint(10, 50)}\n",
    "\n",
    "# Create a RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator=lgb_model, param_distributions=lgb_param_dist, n_iter=100, cv=5, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters: \", random_search.best_params_)\n",
    "\n",
    "# Train the Light GBM Regressor with the best hyperparameters on the entire training set\n",
    "lgb_model = lgb.LGBMRegressor(**random_search.best_params_)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = lgb_model.predict(X_test)\n",
    "\n",
    "# Calculate R2 and RMSE scores on the testing data\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"R2 score on the testing data: \", r2)\n",
    "print(\"RMSE score on the testing data: \", rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1117116",
   "metadata": {},
   "source": [
    "#### Stacking Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09ceab74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tsaijungwang/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/Users/tsaijungwang/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 2 is smaller than n_iter=100. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/Users/tsaijungwang/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 20 is smaller than n_iter=100. Running 20 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/Users/tsaijungwang/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.372e-01, tolerance: 1.655e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/tsaijungwang/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e-01, tolerance: 1.677e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/tsaijungwang/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.492e-01, tolerance: 1.597e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/tsaijungwang/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e-01, tolerance: 1.614e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/tsaijungwang/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.138e-01, tolerance: 1.574e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/tsaijungwang/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.694e-01, tolerance: 1.819e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/tsaijungwang/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.694e-01, tolerance: 1.819e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grids for the models\n",
    "linear_param_grid = {}\n",
    "ridge_param_grid = {\"alpha\": np.arange(0.0001, 1.0, 10), \"solver\": [\"sag\",\"lsqr\"]}\n",
    "lasso_param_grid = {\"alpha\": np.linspace(0.00001, 1, 20)} \n",
    "elasticnet_param_grid = {\"alpha\": uniform(0, 1), \"l1_ratio\": np.arange(0, 1, 0.01)}\n",
    "gb_param_grid = {\"learning_rate\": uniform(0, 1),\n",
    "              \"n_estimators\": randint(50, 100),\n",
    "              \"max_depth\": randint(1, 10),\n",
    "              \"min_samples_split\": randint(2, 10),\n",
    "              \"min_samples_leaf\": randint(1, 5)}\n",
    "lgb_param_grid = {\"num_leaves\": sp_randint(6, 50),\n",
    "              \"max_depth\": sp_randint(1, 20),\n",
    "              \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "              \"n_estimators\": sp_randint(50, 500),\n",
    "              \"min_child_samples\": sp_randint(10, 50)}\n",
    "\n",
    "# Create the models\n",
    "models = [(\"Linear Regression\", LinearRegression(), linear_param_grid),\n",
    "          (\"Ridge Regression\", Ridge(), ridge_param_grid),\n",
    "          (\"Lasso Regression\", Lasso(), lasso_param_grid),\n",
    "          (\"Elastic Net Regression\", ElasticNet(), elasticnet_param_grid),\n",
    "          (\"Gradient Boosting Regression\", GradientBoostingRegressor(), gb_param_grid),\n",
    "          (\"Light GBM Regression\", LGBMRegressor(), lgb_param_grid)]\n",
    "\n",
    "# Create an empty dataframe to store the results\n",
    "results_df = pd.DataFrame(columns=[\"Model\", \"R2 Score\", \"RMSE Score\"])\n",
    "\n",
    "# Loop through the models\n",
    "for name, model, param_grid in models:\n",
    "    # Create a RandomizedSearchCV object for the model\n",
    "    random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=100, cv=kf)\n",
    "    # Fit the model to the training data\n",
    "    random_search.fit(X_train, y_train)\n",
    "    # Train the model with the best hyperparameters on the entire training set\n",
    "    model = model.set_params(**random_search.best_params_)\n",
    "    model.fit(X_train, y_train)\n",
    "    # Make predictions on the testing data\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Calculate the R2 and RMSE scores on the testing data\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    # Append the results to the dataframe\n",
    "    results_df = results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e19fe1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60698bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc11f0fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d95f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
